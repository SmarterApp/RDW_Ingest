package org.opentestsystem.rdw.ingest.service;

import com.amazonaws.AmazonServiceException;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.Headers;
import com.amazonaws.services.s3.model.ObjectMetadata;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.util.StreamUtils;

import java.io.BufferedInputStream;
import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.nio.charset.Charset;
import java.util.Map;
import java.util.Properties;

/**
 * An {@link ArchiveService} implementation that uses Amazon S3.
 * <p>
 * Reiterating that this expects content to be managably small.
 * </p>
 */
public class S3ArchiveService implements ArchiveService, InitializingBean {
    private static final Logger logger = LoggerFactory.getLogger(S3ArchiveService.class);
    private static final String S3SchemePrefix = "s3://";

    private final String bucket;
    private AmazonS3 amazonS3;
    private Charset utf8;

    /**
     * @param root root path, must start with "s3://", e.g. "s3://myBucket"
     */
    S3ArchiveService(final String root) {
        if (!validRoot(root)) {
            throw new IllegalArgumentException("Invalid S3 root " + root);
        }
        // just in case there is an errant trailing slash ...
        String path = root.substring(S3SchemePrefix.length());
        bucket = path.endsWith("/") ? path.substring(0, path.length()-1) : path;

        utf8 = Charset.forName("UTF-8");
    }

    @Autowired
    void setAmazonS3(final AmazonS3 amazonS3) {
        this.amazonS3 = amazonS3;
    }

    @Override
    public void afterPropertiesSet() throws Exception {
        if (!amazonS3.doesBucketExist(bucket)) {
            final String msg = "Invalid S3 bucket " + bucket;
            logger.warn(msg);
            throw new IllegalArgumentException(msg);
        }
    }

    @Override
    public void writeResource(final String location, final String content, final Properties properties) {
        final byte[] data = content.getBytes(utf8);

        final ObjectMetadata metadata = new ObjectMetadata();
        metadata.setContentLength(data.length);
        if (properties != null) {
            for (final Map.Entry<Object, Object> entry : properties.entrySet()) {
                final String key = (String) entry.getKey();
                final String value = entry.getValue().toString();
                metadata.addUserMetadata(key, value);

                // extract S3-specific properties into appropriate metadata
                if (Headers.CONTENT_TYPE.equalsIgnoreCase(key)) {
                    metadata.setContentType((String) entry.getValue());
                }
            }
        }

        // TODO - calculate and provide md5 base64 digest for transmission verification

        try {
            amazonS3.putObject(bucket, location, new ByteArrayInputStream(data), metadata);
        } catch (final AmazonServiceException e) {
            final String msg = "Error writing content to " + bucket + location;
            logger.warn(msg, e);
            throw new RuntimeException(msg, e);
        }
    }

    @Override
    public String readResource(final String location) {
        try (final InputStream is = new BufferedInputStream(amazonS3.getObject(bucket, location).getObjectContent())) {
            return StreamUtils.copyToString(is, Charset.forName("UTF-8"));
        } catch (final AmazonServiceException e) {
            if (e.getStatusCode() == 404 || e.getStatusCode() == 301) {
                return null;
            }
            final String msg = "Amazon error reading content from " + bucket + location;
            logger.warn(msg, e);
            throw e;
        } catch (final IOException e) {
            final String msg = "Error reading content from " + bucket + location;
            logger.warn(msg, e);
            throw new RuntimeException(msg, e);
        }
    }

    @Override
    public Properties readProperties(final String location) {
        final Properties properties = new Properties();

        final ObjectMetadata metadata = amazonS3.getObjectMetadata(bucket, location);
        for (final Map.Entry<String, String> entry : metadata.getUserMetadata().entrySet()) {
            properties.setProperty(entry.getKey(), entry.getValue());
        }

        return properties;
    }

    static boolean validRoot(final String root) {
        return root != null && root.toLowerCase().startsWith(S3SchemePrefix);
    }
}
