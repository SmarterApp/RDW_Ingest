package org.opentestsystem.rdw.ingest.service;

import org.apache.commons.codec.binary.Hex;
import org.apache.commons.codec.digest.DigestUtils;
import org.opentestsystem.rdw.archive.ArchiveService;
import org.opentestsystem.rdw.common.model.ImportContent;
import org.opentestsystem.rdw.common.model.ImportStatus;
import org.opentestsystem.rdw.group.CsvValidationResult;
import org.opentestsystem.rdw.group.CsvValidationService;
import org.opentestsystem.rdw.ingest.auth.SbacUserDetails;
import org.opentestsystem.rdw.ingest.common.model.RdwImport;
import org.opentestsystem.rdw.ingest.repository.RdwImportRepository;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.web.multipart.MultipartFile;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.security.DigestInputStream;
import java.security.MessageDigest;
import java.util.AbstractMap;
import java.util.List;
import java.util.Map;

import static com.google.common.collect.Maps.newHashMap;
import static java.nio.charset.StandardCharsets.UTF_8;
import static org.opentestsystem.rdw.ingest.auth.Authorities.GroupWritePermission;

/**
 * Override the default import service to:<ul>
 *     <li>Permissions-based pre-validation before submitting</li>
 *     <li>Re-process duplicate content instead of ignoring it</li>
 *     <li>Put only the digest in the message payload (instead of the file contents)</li>
 * </ul>
 *
 * The general flow is:<ol>
 *     <li>Calculate digest</li>
 *     <li>Do permissions-based pre-validation</li>
 *     <li>Archive payload and create import record</li>
 *     <li>(return if pre-validation had failures)</li>
 *     <li>Submit work to message queue (even if duplicate)</li>
 * </ol>
 */
@Service("groupImportService")
class GroupImportService extends DefaultImportService {

    private final CsvValidationService validationService;

    @Autowired
    GroupImportService(final RdwImportRepository repository,
                       final ArchiveService archiveService,
                       final ImportSource source,
                       final CsvValidationService validationService) {
        super(repository, archiveService, source);
        this.validationService = validationService;
    }

    @Override
    public RdwImport importContent(final SbacUserDetails user,
                                   final byte[] payload,
                                   final ImportContent content,
                                   final String contentType,
                                   final Map<String, String> params) {

        final String digest = DigestUtils.md5Hex(payload).toUpperCase();

        final Map<String, String> metadata = params == null ? newHashMap() : newHashMap(params);
        final List<CsvValidationResult> validationResults = validationService
                .validate(new ByteArrayInputStream(payload), user.getPermissionScope(GroupWritePermission), metadata);
        final boolean failures = validationResults.stream().anyMatch(result -> !result.isOk());

        // even if there are validation errors, we want to create the import record and archive the payload
        final AbstractMap.SimpleImmutableEntry<RdwImport, Boolean> result = getNewOrExistingImport(
                user, content, contentType, metadata, digest, payload.length, (location, properties) ->
                        archiveService.writeResource(location, payload, properties));
        RdwImport rdwImport = result.getKey();

        // now, if there were validation failures, update the import record and return
        if (failures) {
            rdwImport = repository.update(rdwImport.copy()
                    .status(ImportStatus.BAD_DATA)
                    .message(validationService.toFailureMessage(validationResults))
                    .build());
            return rdwImport;
        }

        // Group imports are always reprocessed even if duplicate (because changes to permissions
        // and organizations could affect the results). So instead of returning, if the found flag
        // is true, then update the import record and continue.
        if (result.getValue()) {
            rdwImport = repository.update(rdwImport.copy().status(ImportStatus.ACCEPTED).build());
            logger.info("Reprocessing {} payload with digest {}", content, digest);
        }

        source.submitContent(digest.getBytes(UTF_8), content, contentType, result.getKey().getId());

        return rdwImport;
    }

    @Override
    public RdwImport importContent(final SbacUserDetails user,
                                   final MultipartFile file,
                                   final ImportContent content,
                                   final String contentType,
                                   final Map<String, String> params) {

        // validate and calculate digest in one go ...
        final Map<String, String> metadata = params == null ? newHashMap() : newHashMap(params);
        final MessageDigest messageDigest = DigestUtils.getMd5Digest();
        final List<CsvValidationResult> validationResults;
        try (final DigestInputStream digestStream = new DigestInputStream(file.getInputStream(), messageDigest)) {
            validationResults = validationService.validate(digestStream, user.getPermissionScope(GroupWritePermission), metadata);
        } catch (final IOException e) {
            logger.warn("Error reading {} file {}: {}", content, file.getName(), e.getMessage());
            throw new IllegalArgumentException(e);
        }
        final boolean failures = validationResults.stream().anyMatch(result -> !result.isOk());
        final String digest = Hex.encodeHexString(messageDigest.digest()).toUpperCase();

        // even if there are validation errors, we want to create the import record and archive the payload
        final AbstractMap.SimpleImmutableEntry<RdwImport, Boolean> result = getNewOrExistingImport(
                user, content, contentType, metadata, digest, file.getSize(), (location, properties) -> {
                    try (final InputStream is = file.getInputStream()) {
                        archiveService.writeResource(location, is, properties);
                    } catch (final IOException e) {
                        logger.warn("Error archiving {} file {} to {}: {}", content, file.getName(), digest, e.getMessage());
                        throw new IllegalArgumentException(e);
                    }
                });
        RdwImport rdwImport = result.getKey();

        // now, if there were validation failures, update the import record and return
        if (failures) {
            rdwImport = repository.update(rdwImport.copy()
                    .status(ImportStatus.BAD_DATA)
                    .message(validationService.toFailureMessage(validationResults))
                    .build());
            return rdwImport;
        }

        // Group imports are always reprocessed even if duplicate (because changes to permissions
        // and organizations could affect the results). So instead of returning, if the found flag
        // is true, then update the import record and continue.
        if (result.getValue()) {
            rdwImport = repository.update(rdwImport.copy().status(ImportStatus.ACCEPTED).build());
            logger.info("Reprocessing {} payload with digest {}", content, digest);
        }

        source.submitContent(digest.getBytes(UTF_8), content, contentType, rdwImport.getId());

        return rdwImport;
    }
}
