package org.opentestsystem.rdw.ingest.migrate.reporting;

import org.opentestsystem.rdw.ingest.common.model.ImportContent;
import org.opentestsystem.rdw.ingest.migrate.reporting.listener.MigrateJobExecutionListener;
import org.opentestsystem.rdw.ingest.migrate.reporting.step.StagingToReportingStepsConfig;
import org.opentestsystem.rdw.ingest.migrate.reporting.step.Warehouse;
import org.opentestsystem.rdw.ingest.migrate.reporting.step.WarehouseCheck;
import org.springframework.batch.core.Job;
import org.springframework.batch.core.JobExecutionListener;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Import;

/**
 * MigrateReportingConfiguration.
 * Spring Batch configuration for the migrate to reporting {@link Job}.
 */
@Configuration
@EnableBatchProcessing
@Import(StagingToReportingStepsConfig.class)
public class MigrateReportingConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;

    public static final String stepWarehouseName = "stepWarehouse";
    public static final String stepWarehouseCheckName = "stepWarehouseCheck";


    @Autowired
    public MigrateReportingConfiguration(final JobBuilderFactory jobBuilderFactory,
                                         final StepBuilderFactory stepBuilderFactory) {

        this.jobBuilderFactory = jobBuilderFactory;
        this.stepBuilderFactory = stepBuilderFactory;
    }

    @Bean
    public JobExecutionListener listener() {
        return new MigrateJobExecutionListener();
    }


    /**
     * This job migrates data from the 'warehouse' to 'reporting' databases.
     * <p>
     * The tables in the warehouse are divided into 'root' and 'children' tables based on their dependencies.
     * All root tables have an import id that last updated a row as well as a delete flag to indicate soft deletes.
     * <p>
     * There are also 'code' tables. They are special 'root's that do not have an explicit delete
     * or import id flags. Code tables are small in size and (if migrated) are moved all at once.
     * It is assumed that the data warehouse takes care of the data integrity in regards to the codes,
     * so it is safe to refresh all the codes.
     * <p>
     * The migration process is done in chunks defined by a range of import ids. The selected range of import ids
     * is analyze to find distinct import contents. Each import content defines a set of tables that have to be migrated.
     * For example {@link ImportContent#CODES} enables codes migration steps.
     * <p>
     * The data is first moved into the staging tables and then migrated to the reporting data mart.
     * <p>
     * Staging tables do not enforce any data relationships and could be loaded in any order.
     * All records from the root tables that have an import id within a batch chunk are moved to the staging tables.
     * The children tables are moved along with the corresponding roots. Note, that if a root is flagged as deleted, the
     * related children are <b>not</b> moved to the staging.
     * <p>
     * The migration from the staging to reporting is designed to preserve a referential integrity of the data in the reporting
     * data mart.
     * <ol>
     * <li>Since almost all the tables depend on the codes, the codes are inserted/updated first:
     * {@link StagingToReportingStepsConfig#upsertCodesStep()}</li>
     * <li>Next, the roots that are flagged as deleted are removed from the data mart along with the referenced data:
     * {@link StagingToReportingStepsConfig#deleteEntitiesStep()}</li>
     * <li>Then each root is processed along with its dependent children. The updates and inserts for the data are determined
     * by comparing staging to the reporting data. An 'update' to the root may trigger a 'delete' to a dependent table. For example, an
     * assessment had one item removed.</li>
     * <li>And finally, the code deletes are performed (if needed): {@link StagingToReportingStepsConfig#deleteCodesStep()}</li>
     * </ol>
     */
    @Bean
    public Job migrateReportingJob(final Step warehouseStep,
                                   final Step warehouseCheckStep,
                                   final Step upsertCodesStep,
                                   final Step deleteEntitiesStep,
                                   final Step deleteCodesStep,
                                   final Step upsertOrganizationsStep,
                                   final Step upsertAsmtsStep,
                                   final Step upsertStudentsAndGroupsStep) {
        try {

            return jobBuilderFactory.get("Migrate Reporting Job")
                    .preventRestart()
                    .listener(listener())
                    .start(warehouseStep)
                    .next(warehouseCheckStep)
                    .next(upsertCodesStep)
                    .next(deleteEntitiesStep)
                    .next(upsertOrganizationsStep)
                    .next(upsertAsmtsStep)
                    .next(upsertStudentsAndGroupsStep)
                    .next(deleteCodesStep)
                    .build();
        } catch (Exception e) {
            return null;
        }
    }

    @Bean
    public Step warehouseStep(final Warehouse warehouse) {
        return stepBuilderFactory.get(stepWarehouseName)
                .tasklet(warehouse).build();
    }

    @Bean
    public Step warehouseCheckStep(final WarehouseCheck warehouseCheck) {
        return stepBuilderFactory.get(stepWarehouseCheckName)
                .tasklet(warehouseCheck).build();
    }
}
