package org.opentestsystem.rdw.ingest.group.service.impl;

import com.google.common.collect.ImmutableMap;
import org.opentestsystem.rdw.archive.ArchiveService;
import org.opentestsystem.rdw.ingest.common.repository.SqlListExecutionRepository;
import org.opentestsystem.rdw.ingest.common.util.LocationStrategy;
import org.opentestsystem.rdw.ingest.common.util.SqlListBuilder;
import org.opentestsystem.rdw.ingest.group.configuration.GroupProcessingSqlConfiguration;
import org.opentestsystem.rdw.ingest.group.service.ProcessingLoadService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;

import static org.opentestsystem.rdw.archive.ArchiveService.RawURI;

/**
 * DefaultProcessingLoadService - This service is responsible for loading the content of the
 * group batch csv file into the warehouse so that other processing may start.
 */
@Service
public class DefaultProcessingLoadService implements ProcessingLoadService {
    private static final Logger logger = LoggerFactory.getLogger(DefaultProcessingLoadService.class);
    private static final String s3Prefix = "s3://";
    private static final String localPrefix = "file://";

    @Value("${sql.load-csv}")
    public String rawSql;

    private final ArchiveService archiveService;

    private final SqlListExecutionRepository repository;
    private final GroupProcessingSqlConfiguration sqlConfiguration;

    @Autowired
    public DefaultProcessingLoadService(final ArchiveService archiveService,
                                        final SqlListExecutionRepository repository,
                                        final GroupProcessingSqlConfiguration sqlConfiguration) {
        this.archiveService = archiveService;
        this.repository = repository;
        this.sqlConfiguration = sqlConfiguration;
    }

    @Override
    public void loadBatch(final String digest, final long batchId) {
        final String location = new LocationStrategy.GroupUploadContentLocationStrategy().location(digest);

        // Check if file already exists in ArchiveService
        if (!archiveService.exists(location)) {
            logger.warn("Unable to locate " + location + " via the archive service");
            throw new IllegalArgumentException("Unable to locate " + location + " via the archive service");
        }

        final SqlListBuilder sqlListBuilder = new SqlListBuilder(sqlConfiguration.getEntities());

        // The sql statement is string parameterized to choose between S3 syntax and local file syntax
        // We want to get the sql statement, substitute in the right source, and then pass the sql statement
        // off to the repository to be executed.
        String uri = archiveService.readProperties(location).getProperty(RawURI);
        final String sqlSource;
        if (uri.startsWith(s3Prefix)) {
            sqlSource = "FROM S3";
        } else if (uri.startsWith(localPrefix)) {
            sqlSource = "LOCAL INFILE";
            uri = uri.substring(localPrefix.length());
        } else {
            throw new IllegalArgumentException("Invalid URI for location " + location);
        }
        sqlListBuilder.addNext(String.format(rawSql, sqlSource));

        repository.execute(sqlListBuilder.build(), ImmutableMap.of("uri", uri, "batch_id", batchId));
    }
}
