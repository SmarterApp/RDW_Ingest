package org.opentestsystem.rdw.ingest.group.service.impl;

import com.google.common.collect.ImmutableMap;
import org.opentestsystem.rdw.archive.ArchiveService;
import org.opentestsystem.rdw.ingest.common.repository.SqlListExecutionRepository;
import org.opentestsystem.rdw.ingest.common.util.LocationStrategy;
import org.opentestsystem.rdw.ingest.common.util.SqlListBuilder;
import org.opentestsystem.rdw.ingest.group.configuration.GroupProcessingSqlConfiguration;
import org.opentestsystem.rdw.ingest.group.service.ProcessingLoadService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.Properties;

import static com.google.common.collect.Lists.newArrayList;
import static org.opentestsystem.rdw.archive.ArchiveService.RawURI;

/**
 * DefaultProcessingLoadService - This service is responsible for loading the content of the
 * group batch csv file into the warehouse so that other processing may start.
 */
@Service
public class DefaultProcessingLoadService implements ProcessingLoadService {
    private static final Logger logger = LoggerFactory.getLogger(DefaultProcessingLoadService.class);
    private static final String s3Prefix = "s3://";
    private static final String localPrefix = "file://";
    private static final List<String> ValidNewline = newArrayList("\\r", "\\n", "\\r\\n");
    private static final List<String> ValidDelimiter = newArrayList(",", "\\t", "|");

    @Value("${sql.load-csv}")
    public String rawSql;

    private final ArchiveService archiveService;

    private final SqlListExecutionRepository repository;
    private final GroupProcessingSqlConfiguration sqlConfiguration;

    @Autowired
    public DefaultProcessingLoadService(final ArchiveService archiveService,
                                        final SqlListExecutionRepository repository,
                                        final GroupProcessingSqlConfiguration sqlConfiguration) {
        this.archiveService = archiveService;
        this.repository = repository;
        this.sqlConfiguration = sqlConfiguration;
    }

    /**
     * Load the batch upload table with data located via the digest of the data
     *
     * @param digest digest of archived file
     * @param batchId batch id
     */
    @Override
    public void loadBatch(final String digest, final long batchId) {
        final String location = new LocationStrategy.GroupUploadContentLocationStrategy().location(digest);

        // Check if file already exists in ArchiveService
        if (!archiveService.exists(location)) {
            logger.warn("Unable to locate " + location + " via the archive service");
            throw new IllegalArgumentException("Unable to locate " + location + " via the archive service");
        }

        // The sql statement is parameterized to allow S3 or local file syntax to be injected,
        // as well as the delimiter and newline sequence. Fetch the sql statement, substitute
        // the source, delimiter and newline, then pass it off to the repository to be executed.
        final Properties props = archiveService.readProperties(location);

        String delimiter = props.getProperty("delimiter");
        if (!ValidDelimiter.contains(delimiter)) {
            logger.warn("Invalid delimiter {} for {}, using default ','", delimiter, location);
            delimiter = ",";
        }

        String newline = props.getProperty("newline");
        if (!ValidNewline.contains(newline)) {
            logger.warn("Invalid newline {} for {}, using default '\\n'", newline, location);
            newline = "\\n";
        }

        String uri = props.getProperty(RawURI);
        final String source;
        if (uri.startsWith(s3Prefix)) {
            source = "FROM S3";
        }
        else if (uri.startsWith(localPrefix)){
            source = "LOCAL INFILE";
            uri = uri.substring(localPrefix.length());
        } else {
            throw new IllegalArgumentException("Invalid URI for location " + location);
        }

        final List<String> sql = new SqlListBuilder(sqlConfiguration.getEntities())
                .addNext(String.format(rawSql, source, delimiter, newline))
                .build();
        repository.execute(sql, ImmutableMap.of("uri", uri, "batch_id", batchId));
    }
}
