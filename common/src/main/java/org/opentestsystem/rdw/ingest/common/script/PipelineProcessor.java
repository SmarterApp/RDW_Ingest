package org.opentestsystem.rdw.ingest.common.script;

import org.opentestsystem.rdw.common.model.ImportException;
import org.opentestsystem.rdw.common.model.ImportStatus;
import org.opentestsystem.rdw.ingest.common.repository.ImportRepository;
import org.opentestsystem.rdw.ingest.common.util.ByteArrayContentWriter;
import org.opentestsystem.rdw.ingest.common.util.TransformedPayloadArchiver;
import org.opentestsystem.rdw.script.Pipeline;
import org.opentestsystem.rdw.script.PipelineBuildException;
import org.opentestsystem.rdw.script.PipelineResults;
import org.opentestsystem.rdw.script.ScriptRuntimeException;

/**
 * Base class for processors that incorporate a pipeline for pre-processing their incoming messages.
 */
public abstract class PipelineProcessor {
    protected final ImportRepository importRepository;
    private final PipelineService pipelineService;

    public PipelineProcessor(final ImportRepository importRepository, final PipelineService pipelineService) {
        this.importRepository = importRepository;
        this.pipelineService = pipelineService;
    }

    /**
     * Get the pipeline by creating it or loading from cache and use it to pre-process the input.
     *
     * @param pipelineType the type of the pipeline to use.
     * @param input the input data to preprocess
     * @param importId the import id used for updating status in case of a failure
     * @param archiver the archiver to use for saving successfully preprocessed data if it varies from the input
     * @return the input altered by the pre-processing or the original input if there is no pipeline
     * @throws PipelineException
     */
    protected byte[] processByPipeline(
            final PipelineType pipelineType,
            final byte[] input,
            final long importId,
            final ByteArrayContentWriter archiver) throws PipelineException {

        // get the pipeline dynamically so it can use the current tenant
        // this expects the factory to deal with tenant and any caching
        Pipeline pipeline;
        try {
            pipeline = pipelineService.getPipeline(pipelineType.code()).orElse(null);
        } catch (final PipelineBuildException e) {
            importRepository.updateStatusAndMessageById(importId, ImportStatus.PIPELINE_FAILURE, e.getMessage());
            throw new PipelineException("Failed to load pipeline " + pipelineType.code(), e);
        }

        try {
            if (pipeline == null) {
                return input;
            } else {
                // Run through pipeline and archive the transformation if any
                final PipelineResults results = pipeline.run(input);
                final byte [] transformedPayload = results.asByteArray();
                if (results.isModified()) {
                    TransformedPayloadArchiver.archive(input, transformedPayload, pipelineType, archiver);
                }
                return transformedPayload;
            }
        } catch (final ScriptRuntimeException e) {
            if (e.getCause() instanceof ImportException) {
                final ImportException ie = (ImportException)e.getCause();
                importRepository.updateStatusAndMessageById(importId, ie.getStatus(), ie.getMessage());
                throw new PipelineException("Input failed validation: {}" + ie.getMessage());
            } else {
                importRepository.updateStatusAndMessageById(importId, ImportStatus.PIPELINE_FAILURE, e.getMessage());
                throw new PipelineException("Pipeline script failure: " + e.getMessage());
            }
        } catch (final Exception e) {
            importRepository.updateStatusAndMessageById(importId, ImportStatus.PIPELINE_FAILURE, e.getMessage());
            throw new PipelineException(
                    pipelineType.code() + " pipeline failed to process input: " + e.getMessage(), e);
        }
    }
}
